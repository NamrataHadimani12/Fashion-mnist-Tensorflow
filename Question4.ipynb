{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2999,
     "status": "ok",
     "timestamp": 1618574932874,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "tN1421DnZ8iZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2998,
     "status": "ok",
     "timestamp": 1618574932876,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "6ELu0Botg-Da"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "executionInfo": {
     "elapsed": 10494,
     "status": "ok",
     "timestamp": 1618574940377,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "1CGywSmJgfh0",
    "outputId": "fe773b29-0ca2-400e-ef07-5af95ecec8a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "(60000, 784) (10000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "# Normalize train and test data\n",
    "x_train = x_train.astype('float64') / 255.\n",
    "x_test = x_test.astype('float64') / 255.\n",
    "\n",
    "# Reshape so that each instance is a linear array of 784 normalized pixel values\n",
    "x_train = x_train.reshape((len(x_train), 784))\n",
    "x_test = x_test.reshape((len(x_test), 784))\n",
    "print (x_train.shape, x_test.shape)\n",
    "\n",
    "# Add random noise to the image\n",
    "noise_factor = 0.2\n",
    "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) \n",
    "\n",
    "# Clip the resulting values so that they don't fall outside the upper and lower normalized value of 0 and 1\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "\n",
    "\n",
    "n = 10  # Number of images to display \n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].numpy().reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 10494,
     "status": "ok",
     "timestamp": 1618574940379,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "3-bM2Spagfka"
   },
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10493,
     "status": "ok",
     "timestamp": 1618574940380,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "a_2Ad6MQgfm7"
   },
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "  sigmoid_output = 1 / (1 + tf.exp(-X))\n",
    "  return sigmoid_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10492,
     "status": "ok",
     "timestamp": 1618574940381,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "23Bo03Cbgfpi"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_actual, y_pred):\n",
    "  element_diff = tf.cast(tf.abs(tf.math.subtract(y_actual,y_pred)),tf.float64)\n",
    "  column_wise_sum = tf.reduce_sum(element_diff,axis = 0)\n",
    "  mean_absolute_error = tf.reduce_mean(column_wise_sum)\n",
    "  return mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10492,
     "status": "ok",
     "timestamp": 1618574940382,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "Ecls53O1kP7E"
   },
   "outputs": [],
   "source": [
    "def forward_pass(X,W1,b1,W2,b2,W3,b3,W4,b4,W5,b5,W6,b6):\n",
    "\n",
    "  hypo_1 = tf.matmul(W1 , X) + b1\n",
    "  relu_act1 = tf.nn.relu(hypo_1)\n",
    "\n",
    "  hypo_2 = tf.matmul(W2 , relu_act1 ) + b2\n",
    "  relu_act2 = tf.nn.relu(hypo_2)\n",
    "\n",
    "  hypo_3 = tf.matmul(W3 , relu_act2 ) + b3\n",
    "  relu_act3 = tf.nn.relu(hypo_3)\n",
    "\n",
    "  hypo_4 = tf.matmul(W4 , relu_act3 ) + b4\n",
    "  relu_act4 = tf.nn.relu(hypo_4)\n",
    "\n",
    "  hypo_5 = tf.matmul(W5 , relu_act4 ) + b5\n",
    "  relu_act5 = tf.nn.relu(hypo_5)\n",
    "\n",
    "  hypo_6 = tf.matmul(W6 , relu_act5 ) + b6\n",
    "  #sigmoid\n",
    "  pred_output = sigmoid(hypo_6)\n",
    "\n",
    "  return pred_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 10491,
     "status": "ok",
     "timestamp": 1618574940382,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "rIYU_-aPiUp0"
   },
   "outputs": [],
   "source": [
    "def autoencoder_decoder(X_train_noisy,X_train, X_test_noisy ,X_test):\n",
    "  no_of_neurons_layer1 = 128\n",
    "  no_of_neurons_layer2 = 64\n",
    "  no_of_neurons_layer3 = 32\n",
    "  #describes the number of types of clothes(10)\n",
    "  no_of_output_units  = 10\n",
    "  no_of_features = X_train.shape[0]\n",
    "\n",
    "  W1 = tf.Variable(tf.random.normal(shape=(no_of_neurons_layer1, no_of_features), dtype=tf.float64) * 0.1)\n",
    "  b1 = tf.Variable(tf.zeros((no_of_neurons_layer1, 1),dtype=tf.float64))\n",
    "\n",
    "  W2 = tf.Variable(tf.random.normal(shape=(no_of_neurons_layer2, no_of_neurons_layer1),dtype=tf.float64) * 0.1)\n",
    "  b2 = tf.Variable(tf.zeros((no_of_neurons_layer2, 1),dtype=tf.float64))\n",
    "\n",
    "  W3 = tf.Variable(tf.random.normal(shape=(no_of_neurons_layer3, no_of_neurons_layer2), dtype=tf.float64) * 0.1)\n",
    "  b3 = tf.Variable(tf.zeros((no_of_neurons_layer3, 1),dtype=tf.float64))\n",
    "\n",
    "  W4 = tf.Variable(tf.random.normal(shape=(no_of_neurons_layer2, no_of_neurons_layer3),dtype=tf.float64) * 0.1)\n",
    "  b4 = tf.Variable(tf.zeros((no_of_neurons_layer2, 1),dtype=tf.float64))\n",
    "\n",
    "  W5 = tf.Variable(tf.random.normal(shape=(no_of_neurons_layer1, no_of_neurons_layer2),dtype=tf.float64) * 0.1)\n",
    "  b5 =tf.Variable(tf.zeros((no_of_neurons_layer1, 1),dtype=tf.float64))\n",
    "\n",
    "  W6 = tf.Variable(tf.random.normal(shape=(no_of_features, no_of_neurons_layer1), dtype=tf.float64) * 0.1)\n",
    "  b6 =tf.Variable(tf.zeros((no_of_features, 1),dtype=tf.float64))\n",
    "\n",
    "  learning_rate = 0.01\n",
    "  adam_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "  train_loss_list =[]\n",
    "  test_loss_list = []\n",
    "\n",
    "  no_of_iter = 500\n",
    "\n",
    "  for i in range(no_of_iter):\n",
    "    #GradientTape will record all the operation till it encounters gradient\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "      train_predictedYProb  = forward_pass(X_train_noisy, W1,b1,W2,b2,W3,b3,W4,b4,W5,b5,W6,b6 )\n",
    "      train_loss = mean_absolute_error(X_train ,train_predictedYProb)\n",
    "    \n",
    "    gradients = tape.gradient(train_loss,[W1,b1,W2,b2,W3,b3,W4,b4,W5,b5,W6,b6])\n",
    "\n",
    "    test_predictedYProb  = forward_pass(X_test_noisy, W1,b1,W2,b2,W3,b3,W4,b4,W5,b5,W6,b6 )\n",
    "    test_loss = mean_absolute_error(X_test ,test_predictedYProb)\n",
    "    \n",
    "    train_loss_list.append(train_loss.numpy())\n",
    "    test_loss_list.append(test_loss.numpy())\n",
    "\n",
    "    adam_optimizer.apply_gradients(zip(gradients , [W1,b1,W2,b2,W3,b3,W4,b4,W5,b5,W6,b6]))\n",
    "\n",
    "    print(\"Train Iteration :\", i , \"Training Loss :\",train_loss.numpy())\n",
    "    print(\"Test Iteration :\", i , \"Test Loss :\",test_loss.numpy())\n",
    "\n",
    "  return train_loss_list , test_loss_list,test_predictedYProb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10487,
     "status": "ok",
     "timestamp": 1618574940383,
     "user": {
      "displayName": "Namrata Hadimani",
      "photoUrl": "",
      "userId": "14346383599399913830"
     },
     "user_tz": -60
    },
    "id": "tgjHr5UHqoox",
    "outputId": "c89d8a70-7af1-4bca-c169-9a16eae0f779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVs3sJgEgfvK",
    "outputId": "d33963bd-df0b-47f0-fdc1-735867301f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration : 0 Training Loss : 299.94123931712096\n",
      "Test Iteration : 0 Test Loss : 298.86757465545486\n",
      "Train Iteration : 1 Training Loss : 268.60806836102245\n",
      "Test Iteration : 1 Test Loss : 267.8179753480903\n",
      "Train Iteration : 2 Training Loss : 226.58187885059323\n",
      "Test Iteration : 2 Test Loss : 226.7160811263986\n",
      "Train Iteration : 3 Training Loss : 195.76849000006342\n",
      "Test Iteration : 3 Test Loss : 196.10983002771408\n",
      "Train Iteration : 4 Training Loss : 187.78767672965998\n",
      "Test Iteration : 4 Test Loss : 188.0850949032382\n",
      "Train Iteration : 5 Training Loss : 181.13102494413013\n",
      "Test Iteration : 5 Test Loss : 181.36225317849423\n",
      "Train Iteration : 6 Training Loss : 174.9740484486953\n",
      "Test Iteration : 6 Test Loss : 175.14083691164396\n",
      "Train Iteration : 7 Training Loss : 172.44346796018377\n",
      "Test Iteration : 7 Test Loss : 172.53466758733867\n",
      "Train Iteration : 8 Training Loss : 170.83181191814958\n",
      "Test Iteration : 8 Test Loss : 170.9070834753586\n",
      "Train Iteration : 9 Training Loss : 168.11481710703328\n",
      "Test Iteration : 9 Test Loss : 168.2708803218984\n",
      "Train Iteration : 10 Training Loss : 166.25621770712962\n",
      "Test Iteration : 10 Test Loss : 166.4891892025695\n",
      "Train Iteration : 11 Training Loss : 163.89981673201157\n",
      "Test Iteration : 11 Test Loss : 164.1231493607202\n",
      "Train Iteration : 12 Training Loss : 161.46228967291617\n",
      "Test Iteration : 12 Test Loss : 161.61461670283725\n",
      "Train Iteration : 13 Training Loss : 159.34065777662013\n",
      "Test Iteration : 13 Test Loss : 159.44722327445248\n",
      "Train Iteration : 14 Training Loss : 156.87154904797814\n",
      "Test Iteration : 14 Test Loss : 156.98569090763885\n",
      "Train Iteration : 15 Training Loss : 154.28699758049746\n",
      "Test Iteration : 15 Test Loss : 154.42833180464456\n",
      "Train Iteration : 16 Training Loss : 151.69325614669881\n",
      "Test Iteration : 16 Test Loss : 151.85179818289367\n",
      "Train Iteration : 17 Training Loss : 148.90497939500258\n",
      "Test Iteration : 17 Test Loss : 149.05116267088698\n",
      "Train Iteration : 18 Training Loss : 146.29764874858088\n",
      "Test Iteration : 18 Test Loss : 146.4124508948733\n",
      "Train Iteration : 19 Training Loss : 143.97287853262625\n",
      "Test Iteration : 19 Test Loss : 144.06055977820108\n",
      "Train Iteration : 20 Training Loss : 141.97072364197126\n",
      "Test Iteration : 20 Test Loss : 142.04836480995925\n",
      "Train Iteration : 21 Training Loss : 140.087586490158\n",
      "Test Iteration : 21 Test Loss : 140.16212448129792\n",
      "Train Iteration : 22 Training Loss : 138.47995882577573\n",
      "Test Iteration : 22 Test Loss : 138.56328122572864\n",
      "Train Iteration : 23 Training Loss : 137.22183849442624\n",
      "Test Iteration : 23 Test Loss : 137.30314094133786\n",
      "Train Iteration : 24 Training Loss : 135.96039891493885\n",
      "Test Iteration : 24 Test Loss : 136.01966033084796\n",
      "Train Iteration : 25 Training Loss : 134.41027151221508\n",
      "Test Iteration : 25 Test Loss : 134.48878487614203\n",
      "Train Iteration : 26 Training Loss : 133.43560635016192\n",
      "Test Iteration : 26 Test Loss : 133.5319292539427\n",
      "Train Iteration : 27 Training Loss : 130.40570788569548\n",
      "Test Iteration : 27 Test Loss : 130.5366810222705\n",
      "Train Iteration : 28 Training Loss : 127.98948930437764\n",
      "Test Iteration : 28 Test Loss : 128.1526394709037\n",
      "Train Iteration : 29 Training Loss : 126.83175017411597\n",
      "Test Iteration : 29 Test Loss : 127.0069981375192\n",
      "Train Iteration : 30 Training Loss : 129.2655501287437\n",
      "Test Iteration : 30 Test Loss : 129.4514684286334\n",
      "Train Iteration : 31 Training Loss : 123.92972589547954\n",
      "Test Iteration : 31 Test Loss : 124.15352312215636\n",
      "Train Iteration : 32 Training Loss : 124.94211807329083\n",
      "Test Iteration : 32 Test Loss : 125.13794916095841\n",
      "Train Iteration : 33 Training Loss : 121.10796663759155\n",
      "Test Iteration : 33 Test Loss : 121.16980292965388\n",
      "Train Iteration : 34 Training Loss : 120.49517323735381\n",
      "Test Iteration : 34 Test Loss : 120.60817680424971\n",
      "Train Iteration : 35 Training Loss : 117.9146657177859\n",
      "Test Iteration : 35 Test Loss : 118.08805984434501\n",
      "Train Iteration : 36 Training Loss : 116.71816471210315\n",
      "Test Iteration : 36 Test Loss : 116.82450575982847\n",
      "Train Iteration : 37 Training Loss : 114.07259786489654\n",
      "Test Iteration : 37 Test Loss : 114.14302058239747\n",
      "Train Iteration : 38 Training Loss : 113.66144436265469\n",
      "Test Iteration : 38 Test Loss : 113.8134630098315\n",
      "Train Iteration : 39 Training Loss : 111.6244070458549\n",
      "Test Iteration : 39 Test Loss : 111.71571435973347\n",
      "Train Iteration : 40 Training Loss : 110.26990505970406\n",
      "Test Iteration : 40 Test Loss : 110.3166071591888\n",
      "Train Iteration : 41 Training Loss : 108.62619744465391\n",
      "Test Iteration : 41 Test Loss : 108.65495403927602\n",
      "Train Iteration : 42 Training Loss : 107.62103378289838\n",
      "Test Iteration : 42 Test Loss : 107.65249866964962\n",
      "Train Iteration : 43 Training Loss : 105.75593734480898\n",
      "Test Iteration : 43 Test Loss : 105.76890382795837\n",
      "Train Iteration : 44 Training Loss : 104.59828710869557\n",
      "Test Iteration : 44 Test Loss : 104.63006978662423\n",
      "Train Iteration : 45 Training Loss : 103.49566948084465\n",
      "Test Iteration : 45 Test Loss : 103.55811384005067\n",
      "Train Iteration : 46 Training Loss : 102.63234215639454\n",
      "Test Iteration : 46 Test Loss : 102.67386127633125\n",
      "Train Iteration : 47 Training Loss : 100.73592932011796\n",
      "Test Iteration : 47 Test Loss : 100.77233554191267\n",
      "Train Iteration : 48 Training Loss : 99.76246870959031\n",
      "Test Iteration : 48 Test Loss : 99.78765429420388\n",
      "Train Iteration : 49 Training Loss : 99.14478266879918\n",
      "Test Iteration : 49 Test Loss : 99.14860542538466\n",
      "Train Iteration : 50 Training Loss : 99.26667968761487\n",
      "Test Iteration : 50 Test Loss : 99.29312788485855\n",
      "Train Iteration : 51 Training Loss : 99.32493044546656\n",
      "Test Iteration : 51 Test Loss : 99.3705007633091\n",
      "Train Iteration : 52 Training Loss : 99.29509799183316\n",
      "Test Iteration : 52 Test Loss : 99.27457979445303\n",
      "Train Iteration : 53 Training Loss : 95.48817590481181\n",
      "Test Iteration : 53 Test Loss : 95.51901537968659\n",
      "Train Iteration : 54 Training Loss : 97.2197397955734\n",
      "Test Iteration : 54 Test Loss : 97.25856413391485\n",
      "Train Iteration : 55 Training Loss : 98.56543885908505\n",
      "Test Iteration : 55 Test Loss : 98.59089031650198\n",
      "Train Iteration : 56 Training Loss : 94.11428602151602\n",
      "Test Iteration : 56 Test Loss : 94.12204105753538\n",
      "Train Iteration : 57 Training Loss : 96.33389906989412\n",
      "Test Iteration : 57 Test Loss : 96.3157937762076\n",
      "Train Iteration : 58 Training Loss : 95.35569301440744\n",
      "Test Iteration : 58 Test Loss : 95.34567526720204\n",
      "Train Iteration : 59 Training Loss : 93.17178723340419\n",
      "Test Iteration : 59 Test Loss : 93.14401112469001\n",
      "Train Iteration : 60 Training Loss : 95.3872418564836\n",
      "Test Iteration : 60 Test Loss : 95.38382597260524\n",
      "Train Iteration : 61 Training Loss : 92.11120073945827\n",
      "Test Iteration : 61 Test Loss : 92.08237517695173\n",
      "Train Iteration : 62 Training Loss : 92.93070416695707\n",
      "Test Iteration : 62 Test Loss : 92.88245958049687\n",
      "Train Iteration : 63 Training Loss : 91.90248767350188\n",
      "Test Iteration : 63 Test Loss : 91.82925644088506\n",
      "Train Iteration : 64 Training Loss : 90.75464018579953\n",
      "Test Iteration : 64 Test Loss : 90.70764383800342\n",
      "Train Iteration : 65 Training Loss : 91.43971011156238\n",
      "Test Iteration : 65 Test Loss : 91.41403520881185\n",
      "Train Iteration : 66 Training Loss : 89.55550074231792\n",
      "Test Iteration : 66 Test Loss : 89.54015581002028\n",
      "Train Iteration : 67 Training Loss : 91.18151410972165\n",
      "Test Iteration : 67 Test Loss : 91.1348490646396\n",
      "Train Iteration : 68 Training Loss : 91.21914559082063\n",
      "Test Iteration : 68 Test Loss : 91.19942205362551\n",
      "Train Iteration : 69 Training Loss : 88.92969875480635\n",
      "Test Iteration : 69 Test Loss : 88.88517775764011\n",
      "Train Iteration : 70 Training Loss : 90.74867901317737\n",
      "Test Iteration : 70 Test Loss : 90.69610578176724\n",
      "Train Iteration : 71 Training Loss : 90.06879040209294\n",
      "Test Iteration : 71 Test Loss : 89.99401137969491\n",
      "Train Iteration : 72 Training Loss : 88.47050250444306\n",
      "Test Iteration : 72 Test Loss : 88.40789265480016\n",
      "Train Iteration : 73 Training Loss : 90.34316471755321\n",
      "Test Iteration : 73 Test Loss : 90.26497706980403\n",
      "Train Iteration : 74 Training Loss : 87.97867920164376\n",
      "Test Iteration : 74 Test Loss : 87.92365033317864\n",
      "Train Iteration : 75 Training Loss : 88.34487446855857\n",
      "Test Iteration : 75 Test Loss : 88.28864774166703\n",
      "Train Iteration : 76 Training Loss : 88.26861977132494\n",
      "Test Iteration : 76 Test Loss : 88.18401733381225\n",
      "Train Iteration : 77 Training Loss : 86.69539753855634\n",
      "Test Iteration : 77 Test Loss : 86.63034060681645\n",
      "Train Iteration : 78 Training Loss : 87.03343267179208\n",
      "Test Iteration : 78 Test Loss : 86.9745400430177\n",
      "Train Iteration : 79 Training Loss : 86.6032265589281\n",
      "Test Iteration : 79 Test Loss : 86.56696730273048\n",
      "Train Iteration : 80 Training Loss : 85.62494233760518\n",
      "Test Iteration : 80 Test Loss : 85.56567067436008\n",
      "Train Iteration : 81 Training Loss : 85.47816653674779\n",
      "Test Iteration : 81 Test Loss : 85.40994445459594\n",
      "Train Iteration : 82 Training Loss : 85.38138027133613\n",
      "Test Iteration : 82 Test Loss : 85.32380499789316\n",
      "Train Iteration : 83 Training Loss : 85.33717911081526\n",
      "Test Iteration : 83 Test Loss : 85.2833623566953\n",
      "Train Iteration : 84 Training Loss : 84.57387757534897\n",
      "Test Iteration : 84 Test Loss : 84.50906056781248\n",
      "Train Iteration : 85 Training Loss : 84.4198369797215\n",
      "Test Iteration : 85 Test Loss : 84.34066369775799\n",
      "Train Iteration : 86 Training Loss : 84.16782565362007\n",
      "Test Iteration : 86 Test Loss : 84.09346031167861\n",
      "Train Iteration : 87 Training Loss : 84.6157491746625\n",
      "Test Iteration : 87 Test Loss : 84.54631218868687\n",
      "Train Iteration : 88 Training Loss : 85.6505618236857\n",
      "Test Iteration : 88 Test Loss : 85.53100089957002\n",
      "Train Iteration : 89 Training Loss : 85.26383557995428\n",
      "Test Iteration : 89 Test Loss : 85.19709163494231\n",
      "Train Iteration : 90 Training Loss : 85.27901123749459\n",
      "Test Iteration : 90 Test Loss : 85.2021571876143\n",
      "Train Iteration : 91 Training Loss : 83.68064767416132\n",
      "Test Iteration : 91 Test Loss : 83.6023827229725\n",
      "Train Iteration : 92 Training Loss : 83.64158688081935\n",
      "Test Iteration : 92 Test Loss : 83.53656613655983\n",
      "Train Iteration : 93 Training Loss : 83.02778053948563\n",
      "Test Iteration : 93 Test Loss : 82.93492034176987\n",
      "Train Iteration : 94 Training Loss : 83.87793474270805\n",
      "Test Iteration : 94 Test Loss : 83.8125016009579\n",
      "Train Iteration : 95 Training Loss : 84.54132834407802\n",
      "Test Iteration : 95 Test Loss : 84.42519970347394\n",
      "Train Iteration : 96 Training Loss : 83.68594270211797\n",
      "Test Iteration : 96 Test Loss : 83.62035129345564\n",
      "Train Iteration : 97 Training Loss : 83.28988722697463\n",
      "Test Iteration : 97 Test Loss : 83.23885183286636\n",
      "Train Iteration : 98 Training Loss : 82.42710086793596\n",
      "Test Iteration : 98 Test Loss : 82.3634620619798\n",
      "Train Iteration : 99 Training Loss : 83.49482700145535\n",
      "Test Iteration : 99 Test Loss : 83.4391807028565\n",
      "Train Iteration : 100 Training Loss : 82.94214423690828\n",
      "Test Iteration : 100 Test Loss : 82.85691574664419\n",
      "Train Iteration : 101 Training Loss : 83.08547558694495\n",
      "Test Iteration : 101 Test Loss : 83.04685228995771\n",
      "Train Iteration : 102 Training Loss : 81.9722309107709\n",
      "Test Iteration : 102 Test Loss : 81.90583082982828\n",
      "Train Iteration : 103 Training Loss : 82.0246968532145\n",
      "Test Iteration : 103 Test Loss : 81.97609596175897\n",
      "Train Iteration : 104 Training Loss : 81.56002984760156\n",
      "Test Iteration : 104 Test Loss : 81.53541573878063\n",
      "Train Iteration : 105 Training Loss : 81.52392823727499\n",
      "Test Iteration : 105 Test Loss : 81.5011866653395\n",
      "Train Iteration : 106 Training Loss : 81.60082832883148\n",
      "Test Iteration : 106 Test Loss : 81.57042772079927\n",
      "Train Iteration : 107 Training Loss : 81.6991046420719\n",
      "Test Iteration : 107 Test Loss : 81.65299831702106\n",
      "Train Iteration : 108 Training Loss : 82.08219779377063\n",
      "Test Iteration : 108 Test Loss : 82.05900156755563\n",
      "Train Iteration : 109 Training Loss : 82.87865241858724\n",
      "Test Iteration : 109 Test Loss : 82.82993366246151\n",
      "Train Iteration : 110 Training Loss : 82.94856376395494\n",
      "Test Iteration : 110 Test Loss : 82.93498056160806\n",
      "Train Iteration : 111 Training Loss : 82.71157587868296\n",
      "Test Iteration : 111 Test Loss : 82.67850877717837\n",
      "Train Iteration : 112 Training Loss : 80.82537627874957\n",
      "Test Iteration : 112 Test Loss : 80.805127366176\n",
      "Train Iteration : 113 Training Loss : 80.780602837463\n",
      "Test Iteration : 113 Test Loss : 80.73999230166825\n",
      "Train Iteration : 114 Training Loss : 81.45242105379913\n",
      "Test Iteration : 114 Test Loss : 81.4178156994909\n",
      "Train Iteration : 115 Training Loss : 82.02915789728043\n",
      "Test Iteration : 115 Test Loss : 82.02664063814933\n",
      "Train Iteration : 116 Training Loss : 81.70927703315769\n",
      "Test Iteration : 116 Test Loss : 81.67114856725323\n",
      "Train Iteration : 117 Training Loss : 80.46661713540657\n",
      "Test Iteration : 117 Test Loss : 80.4429406360683\n",
      "Train Iteration : 118 Training Loss : 80.13911370377816\n",
      "Test Iteration : 118 Test Loss : 80.14298533699116\n",
      "Train Iteration : 119 Training Loss : 80.82242119476655\n",
      "Test Iteration : 119 Test Loss : 80.83353066907138\n",
      "Train Iteration : 120 Training Loss : 81.27651924998507\n",
      "Test Iteration : 120 Test Loss : 81.28130178643332\n",
      "Train Iteration : 121 Training Loss : 80.86529257934923\n",
      "Test Iteration : 121 Test Loss : 80.86477314435093\n",
      "Train Iteration : 122 Training Loss : 79.89383875155868\n",
      "Test Iteration : 122 Test Loss : 79.91501201404792\n",
      "Train Iteration : 123 Training Loss : 79.43056196403087\n",
      "Test Iteration : 123 Test Loss : 79.43832538150342\n",
      "Train Iteration : 124 Training Loss : 79.95532229470533\n",
      "Test Iteration : 124 Test Loss : 79.96910987084252\n",
      "Train Iteration : 125 Training Loss : 80.18192401206639\n",
      "Test Iteration : 125 Test Loss : 80.21762596124991\n",
      "Train Iteration : 126 Training Loss : 80.2029165444614\n",
      "Test Iteration : 126 Test Loss : 80.21319959163154\n",
      "Train Iteration : 127 Training Loss : 79.39552361023948\n",
      "Test Iteration : 127 Test Loss : 79.40286619235997\n",
      "Train Iteration : 128 Training Loss : 78.81910113988015\n",
      "Test Iteration : 128 Test Loss : 78.84769677902786\n",
      "Train Iteration : 129 Training Loss : 78.8163713928382\n",
      "Test Iteration : 129 Test Loss : 78.85643749110604\n",
      "Train Iteration : 130 Training Loss : 78.99812656914307\n",
      "Test Iteration : 130 Test Loss : 79.02366890016222\n",
      "Train Iteration : 131 Training Loss : 79.56661621525376\n",
      "Test Iteration : 131 Test Loss : 79.57928630439365\n",
      "Train Iteration : 132 Training Loss : 79.7753405067398\n",
      "Test Iteration : 132 Test Loss : 79.81282903345982\n",
      "Train Iteration : 133 Training Loss : 80.283840052455\n",
      "Test Iteration : 133 Test Loss : 80.32122447268551\n",
      "Train Iteration : 134 Training Loss : 79.19965530282705\n",
      "Test Iteration : 134 Test Loss : 79.24051832403869\n",
      "Train Iteration : 135 Training Loss : 78.45372067582139\n",
      "Test Iteration : 135 Test Loss : 78.49502456934427\n",
      "Train Iteration : 136 Training Loss : 78.0352051097591\n",
      "Test Iteration : 136 Test Loss : 78.06771966877331\n",
      "Train Iteration : 137 Training Loss : 78.19345780344706\n",
      "Test Iteration : 137 Test Loss : 78.23025370600689\n",
      "Train Iteration : 138 Training Loss : 78.43744392660012\n",
      "Test Iteration : 138 Test Loss : 78.4940147889272\n",
      "Train Iteration : 139 Training Loss : 78.71989555868453\n",
      "Test Iteration : 139 Test Loss : 78.77169952341248\n",
      "Train Iteration : 140 Training Loss : 79.52182460602799\n",
      "Test Iteration : 140 Test Loss : 79.55553198459333\n",
      "Train Iteration : 141 Training Loss : 78.54294208720972\n",
      "Test Iteration : 141 Test Loss : 78.61003314307926\n",
      "Train Iteration : 142 Training Loss : 77.90680511949776\n",
      "Test Iteration : 142 Test Loss : 77.9783138692002\n",
      "Train Iteration : 143 Training Loss : 77.40553748010649\n",
      "Test Iteration : 143 Test Loss : 77.46020796386969\n",
      "Train Iteration : 144 Training Loss : 77.44737952013041\n",
      "Test Iteration : 144 Test Loss : 77.50966675806109\n",
      "Train Iteration : 145 Training Loss : 77.67781190360934\n",
      "Test Iteration : 145 Test Loss : 77.75530838802439\n",
      "Train Iteration : 146 Training Loss : 77.8568256219441\n",
      "Test Iteration : 146 Test Loss : 77.92245795751776\n",
      "Train Iteration : 147 Training Loss : 78.66396569428913\n",
      "Test Iteration : 147 Test Loss : 78.72186957181854\n",
      "Train Iteration : 148 Training Loss : 78.30183808900021\n",
      "Test Iteration : 148 Test Loss : 78.4014220769646\n",
      "Train Iteration : 149 Training Loss : 77.97809319958802\n",
      "Test Iteration : 149 Test Loss : 78.06608005055612\n",
      "Train Iteration : 150 Training Loss : 77.14583992062462\n",
      "Test Iteration : 150 Test Loss : 77.21049077179855\n",
      "Train Iteration : 151 Training Loss : 77.03031244527484\n",
      "Test Iteration : 151 Test Loss : 77.11370663730541\n",
      "Train Iteration : 152 Training Loss : 76.56328380701952\n",
      "Test Iteration : 152 Test Loss : 76.66958050550402\n",
      "Train Iteration : 153 Training Loss : 76.68589944791007\n",
      "Test Iteration : 153 Test Loss : 76.77218736293759\n",
      "Train Iteration : 154 Training Loss : 76.90422548561037\n",
      "Test Iteration : 154 Test Loss : 76.98684989268438\n",
      "Train Iteration : 155 Training Loss : 76.8677787643316\n",
      "Test Iteration : 155 Test Loss : 76.9742881031343\n",
      "Train Iteration : 156 Training Loss : 77.32335368390535\n",
      "Test Iteration : 156 Test Loss : 77.42748559403657\n",
      "Train Iteration : 157 Training Loss : 77.28646104561749\n",
      "Test Iteration : 157 Test Loss : 77.38942796876077\n",
      "Train Iteration : 158 Training Loss : 78.20113179993176\n",
      "Test Iteration : 158 Test Loss : 78.26958697439991\n",
      "Train Iteration : 159 Training Loss : 76.69656364858564\n",
      "Test Iteration : 159 Test Loss : 76.7824003087045\n",
      "Train Iteration : 160 Training Loss : 76.16781272273144\n",
      "Test Iteration : 160 Test Loss : 76.26127444072448\n",
      "Train Iteration : 161 Training Loss : 75.75550315670033\n",
      "Test Iteration : 161 Test Loss : 75.86197509227567\n",
      "Train Iteration : 162 Training Loss : 75.97104273099723\n",
      "Test Iteration : 162 Test Loss : 76.06758260712598\n",
      "Train Iteration : 163 Training Loss : 76.36842172415278\n",
      "Test Iteration : 163 Test Loss : 76.45463761926389\n",
      "Train Iteration : 164 Training Loss : 76.74790493588776\n",
      "Test Iteration : 164 Test Loss : 76.84271294692785\n",
      "Train Iteration : 165 Training Loss : 77.31253766730184\n",
      "Test Iteration : 165 Test Loss : 77.39552274534735\n",
      "Train Iteration : 166 Training Loss : 76.42016226586308\n",
      "Test Iteration : 166 Test Loss : 76.51496183679097\n",
      "Train Iteration : 167 Training Loss : 75.8443599462818\n",
      "Test Iteration : 167 Test Loss : 75.96903632483448\n",
      "Train Iteration : 168 Training Loss : 75.33991805351697\n",
      "Test Iteration : 168 Test Loss : 75.44010762168713\n",
      "Train Iteration : 169 Training Loss : 75.6049180983971\n",
      "Test Iteration : 169 Test Loss : 75.69597272582232\n",
      "Train Iteration : 170 Training Loss : 75.63435290975004\n",
      "Test Iteration : 170 Test Loss : 75.74160869612189\n",
      "Train Iteration : 171 Training Loss : 75.88032231429342\n",
      "Test Iteration : 171 Test Loss : 75.97998398357447\n",
      "Train Iteration : 172 Training Loss : 76.17228017711928\n",
      "Test Iteration : 172 Test Loss : 76.26511636510074\n",
      "Train Iteration : 173 Training Loss : 75.77041303840159\n",
      "Test Iteration : 173 Test Loss : 75.87740722445177\n",
      "Train Iteration : 174 Training Loss : 75.12039048812713\n",
      "Test Iteration : 174 Test Loss : 75.21547173846324\n",
      "Train Iteration : 175 Training Loss : 74.61284956666432\n",
      "Test Iteration : 175 Test Loss : 74.72301427610438\n",
      "Train Iteration : 176 Training Loss : 74.80427390840399\n",
      "Test Iteration : 176 Test Loss : 74.93958663087011\n",
      "Train Iteration : 177 Training Loss : 74.4346451456128\n",
      "Test Iteration : 177 Test Loss : 74.55169100878639\n",
      "Train Iteration : 178 Training Loss : 74.85298108675104\n",
      "Test Iteration : 178 Test Loss : 74.9608770604406\n",
      "Train Iteration : 179 Training Loss : 75.2021990242675\n",
      "Test Iteration : 179 Test Loss : 75.33450628705448\n",
      "Train Iteration : 180 Training Loss : 75.67897278249711\n",
      "Test Iteration : 180 Test Loss : 75.81586902445794\n",
      "Train Iteration : 181 Training Loss : 76.19369832569035\n",
      "Test Iteration : 181 Test Loss : 76.32844346012969\n",
      "Train Iteration : 182 Training Loss : 75.96373273209304\n",
      "Test Iteration : 182 Test Loss : 76.06537474429648\n",
      "Train Iteration : 183 Training Loss : 76.03855095458088\n",
      "Test Iteration : 183 Test Loss : 76.1434143523961\n",
      "Train Iteration : 184 Training Loss : 74.3279755336282\n",
      "Test Iteration : 184 Test Loss : 74.44242748861438\n",
      "Train Iteration : 185 Training Loss : 74.67742836048764\n",
      "Test Iteration : 185 Test Loss : 74.81786337995452\n",
      "Train Iteration : 186 Training Loss : 74.98429990212533\n",
      "Test Iteration : 186 Test Loss : 75.10677787752701\n",
      "Train Iteration : 187 Training Loss : 75.81629969112922\n",
      "Test Iteration : 187 Test Loss : 75.95447097240405\n",
      "Train Iteration : 188 Training Loss : 74.94169142091665\n",
      "Test Iteration : 188 Test Loss : 75.10265050928196\n",
      "Train Iteration : 189 Training Loss : 74.18076749404266\n",
      "Test Iteration : 189 Test Loss : 74.3147296328314\n",
      "Train Iteration : 190 Training Loss : 73.7109022017786\n",
      "Test Iteration : 190 Test Loss : 73.85765000786782\n",
      "Train Iteration : 191 Training Loss : 74.46836406635714\n",
      "Test Iteration : 191 Test Loss : 74.62068764896357\n",
      "Train Iteration : 192 Training Loss : 74.21140239695443\n",
      "Test Iteration : 192 Test Loss : 74.3344277854167\n",
      "Train Iteration : 193 Training Loss : 73.9677183573025\n",
      "Test Iteration : 193 Test Loss : 74.10612092200937\n",
      "Train Iteration : 194 Training Loss : 73.6441594653933\n",
      "Test Iteration : 194 Test Loss : 73.81798569227813\n",
      "Train Iteration : 195 Training Loss : 73.0669607675832\n",
      "Test Iteration : 195 Test Loss : 73.23497645549442\n",
      "Train Iteration : 196 Training Loss : 73.34630389541077\n",
      "Test Iteration : 196 Test Loss : 73.49068954501108\n",
      "Train Iteration : 197 Training Loss : 73.30287938390241\n",
      "Test Iteration : 197 Test Loss : 73.49077926774142\n",
      "Train Iteration : 198 Training Loss : 73.615668679033\n",
      "Test Iteration : 198 Test Loss : 73.79055957835838\n",
      "Train Iteration : 199 Training Loss : 73.40208979271073\n",
      "Test Iteration : 199 Test Loss : 73.56598412320882\n",
      "Train Iteration : 200 Training Loss : 73.50383828195027\n",
      "Test Iteration : 200 Test Loss : 73.69301214323727\n",
      "Train Iteration : 201 Training Loss : 73.14995802640495\n",
      "Test Iteration : 201 Test Loss : 73.31780005564842\n",
      "Train Iteration : 202 Training Loss : 72.95601823323997\n",
      "Test Iteration : 202 Test Loss : 73.12562306140913\n",
      "Train Iteration : 203 Training Loss : 73.00423739320765\n",
      "Test Iteration : 203 Test Loss : 73.20256283567282\n",
      "Train Iteration : 204 Training Loss : 72.87966382578428\n",
      "Test Iteration : 204 Test Loss : 73.05871872611417\n",
      "Train Iteration : 205 Training Loss : 72.99797047049313\n",
      "Test Iteration : 205 Test Loss : 73.17993600173767\n",
      "Train Iteration : 206 Training Loss : 73.46095618345787\n",
      "Test Iteration : 206 Test Loss : 73.65270956344868\n",
      "Train Iteration : 207 Training Loss : 73.54205914202716\n",
      "Test Iteration : 207 Test Loss : 73.71158051800612\n",
      "Train Iteration : 208 Training Loss : 74.29033908138562\n",
      "Test Iteration : 208 Test Loss : 74.46917550708116\n",
      "Train Iteration : 209 Training Loss : 73.43371016702578\n",
      "Test Iteration : 209 Test Loss : 73.62877093276926\n",
      "Train Iteration : 210 Training Loss : 72.96295574701722\n",
      "Test Iteration : 210 Test Loss : 73.12670264041577\n",
      "Train Iteration : 211 Training Loss : 72.15161882820482\n",
      "Test Iteration : 211 Test Loss : 72.34326713335055\n",
      "Train Iteration : 212 Training Loss : 71.94364461190428\n",
      "Test Iteration : 212 Test Loss : 72.1560410443161\n",
      "Train Iteration : 213 Training Loss : 71.86205365377234\n",
      "Test Iteration : 213 Test Loss : 72.04786694213463\n",
      "Train Iteration : 214 Training Loss : 71.8052158367633\n",
      "Test Iteration : 214 Test Loss : 72.00694886892845\n",
      "Train Iteration : 215 Training Loss : 72.05674230528436\n",
      "Test Iteration : 215 Test Loss : 72.2495976702764\n",
      "Train Iteration : 216 Training Loss : 72.33077047891987\n",
      "Test Iteration : 216 Test Loss : 72.52183317743693\n",
      "Train Iteration : 217 Training Loss : 73.33977678776193\n",
      "Test Iteration : 217 Test Loss : 73.55859113667631\n",
      "Train Iteration : 218 Training Loss : 73.3716201485473\n",
      "Test Iteration : 218 Test Loss : 73.55394522844907\n",
      "Train Iteration : 219 Training Loss : 73.95444702247504\n",
      "Test Iteration : 219 Test Loss : 74.13423378344204\n",
      "Train Iteration : 220 Training Loss : 72.484464979418\n",
      "Test Iteration : 220 Test Loss : 72.68725832367548\n",
      "Train Iteration : 221 Training Loss : 71.5423227950688\n",
      "Test Iteration : 221 Test Loss : 71.72811059151744\n",
      "Train Iteration : 222 Training Loss : 71.21067353289298\n",
      "Test Iteration : 222 Test Loss : 71.41327803559471\n",
      "Train Iteration : 223 Training Loss : 71.68362236459517\n",
      "Test Iteration : 223 Test Loss : 71.89773404804008\n",
      "Train Iteration : 224 Training Loss : 72.51385504174027\n",
      "Test Iteration : 224 Test Loss : 72.72099778573447\n",
      "Train Iteration : 225 Training Loss : 72.4565790782353\n",
      "Test Iteration : 225 Test Loss : 72.6696625401465\n",
      "Train Iteration : 226 Training Loss : 72.52794960701624\n",
      "Test Iteration : 226 Test Loss : 72.7474264313178\n",
      "Train Iteration : 227 Training Loss : 71.45056157999495\n",
      "Test Iteration : 227 Test Loss : 71.64340966121172\n",
      "Train Iteration : 228 Training Loss : 70.87642279133944\n",
      "Test Iteration : 228 Test Loss : 71.09906655729385\n",
      "Train Iteration : 229 Training Loss : 70.93191285778994\n",
      "Test Iteration : 229 Test Loss : 71.1605866719832\n",
      "Train Iteration : 230 Training Loss : 71.35370377019983\n",
      "Test Iteration : 230 Test Loss : 71.56154394439065\n",
      "Train Iteration : 231 Training Loss : 72.06139199382058\n",
      "Test Iteration : 231 Test Loss : 72.29435384486224\n",
      "Train Iteration : 232 Training Loss : 71.69654201898189\n",
      "Test Iteration : 232 Test Loss : 71.90604715709549\n",
      "Train Iteration : 233 Training Loss : 71.57007097510647\n",
      "Test Iteration : 233 Test Loss : 71.77746559202042\n",
      "Train Iteration : 234 Training Loss : 71.1644422278706\n",
      "Test Iteration : 234 Test Loss : 71.41059093821019\n",
      "Train Iteration : 235 Training Loss : 70.62208089813305\n",
      "Test Iteration : 235 Test Loss : 70.84536636892396\n",
      "Train Iteration : 236 Training Loss : 70.39716433801925\n",
      "Test Iteration : 236 Test Loss : 70.63014459961575\n",
      "Train Iteration : 237 Training Loss : 70.51515976741537\n",
      "Test Iteration : 237 Test Loss : 70.77181440791776\n",
      "Train Iteration : 238 Training Loss : 70.65627582036555\n",
      "Test Iteration : 238 Test Loss : 70.88310624437989\n",
      "Train Iteration : 239 Training Loss : 70.71377390456075\n",
      "Test Iteration : 239 Test Loss : 70.95594660221599\n",
      "Train Iteration : 240 Training Loss : 71.20878225697214\n",
      "Test Iteration : 240 Test Loss : 71.43355036800362\n",
      "Train Iteration : 241 Training Loss : 71.5964366899322\n",
      "Test Iteration : 241 Test Loss : 71.82665639998089\n",
      "Train Iteration : 242 Training Loss : 73.26094139327745\n",
      "Test Iteration : 242 Test Loss : 73.50933816492926\n",
      "Train Iteration : 243 Training Loss : 71.86843336774719\n",
      "Test Iteration : 243 Test Loss : 72.10372278232258\n",
      "Train Iteration : 244 Training Loss : 71.03373322084059\n",
      "Test Iteration : 244 Test Loss : 71.2550937406122\n",
      "Train Iteration : 245 Training Loss : 70.31668710542803\n",
      "Test Iteration : 245 Test Loss : 70.56038815410349\n",
      "Train Iteration : 246 Training Loss : 70.15286777130714\n",
      "Test Iteration : 246 Test Loss : 70.37825346884837\n",
      "Train Iteration : 247 Training Loss : 70.15667551606495\n",
      "Test Iteration : 247 Test Loss : 70.41378469662436\n",
      "Train Iteration : 248 Training Loss : 70.51133595731422\n",
      "Test Iteration : 248 Test Loss : 70.76974759036864\n",
      "Train Iteration : 249 Training Loss : 71.44719328731706\n",
      "Test Iteration : 249 Test Loss : 71.67428457858219\n",
      "Train Iteration : 250 Training Loss : 70.81226899699338\n",
      "Test Iteration : 250 Test Loss : 71.0717249257382\n",
      "Train Iteration : 251 Training Loss : 70.4376449461621\n",
      "Test Iteration : 251 Test Loss : 70.69472470178485\n",
      "Train Iteration : 252 Training Loss : 70.04169800876248\n",
      "Test Iteration : 252 Test Loss : 70.28603787829243\n",
      "Train Iteration : 253 Training Loss : 69.76419033479996\n",
      "Test Iteration : 253 Test Loss : 70.03139516530561\n",
      "Train Iteration : 254 Training Loss : 69.36994500470702\n",
      "Test Iteration : 254 Test Loss : 69.62697357114685\n",
      "Train Iteration : 255 Training Loss : 69.34812459844952\n",
      "Test Iteration : 255 Test Loss : 69.60933255222888\n",
      "Train Iteration : 256 Training Loss : 69.52535697984024\n",
      "Test Iteration : 256 Test Loss : 69.80330863567595\n",
      "Train Iteration : 257 Training Loss : 69.67711713036292\n",
      "Test Iteration : 257 Test Loss : 69.93836633584363\n",
      "Train Iteration : 258 Training Loss : 70.11878534180322\n",
      "Test Iteration : 258 Test Loss : 70.3916393584284\n",
      "Train Iteration : 259 Training Loss : 70.38447883791146\n",
      "Test Iteration : 259 Test Loss : 70.65666372947005\n",
      "Train Iteration : 260 Training Loss : 71.54804293776229\n",
      "Test Iteration : 260 Test Loss : 71.77623415571766\n",
      "Train Iteration : 261 Training Loss : 70.87704616649545\n",
      "Test Iteration : 261 Test Loss : 71.14048352591733\n",
      "Train Iteration : 262 Training Loss : 70.0989550561561\n",
      "Test Iteration : 262 Test Loss : 70.35048843676812\n",
      "Train Iteration : 263 Training Loss : 69.04445257524839\n",
      "Test Iteration : 263 Test Loss : 69.31253259496867\n",
      "Train Iteration : 264 Training Loss : 68.93663818908085\n",
      "Test Iteration : 264 Test Loss : 69.23087441708773\n",
      "Train Iteration : 265 Training Loss : 69.11076436685624\n",
      "Test Iteration : 265 Test Loss : 69.39314180059007\n",
      "Train Iteration : 266 Training Loss : 69.21079307104358\n",
      "Test Iteration : 266 Test Loss : 69.5030126300308\n",
      "Train Iteration : 267 Training Loss : 69.60486961964696\n",
      "Test Iteration : 267 Test Loss : 69.88158701463279\n",
      "Train Iteration : 268 Training Loss : 69.93761591996048\n",
      "Test Iteration : 268 Test Loss : 70.22609009565852\n",
      "Train Iteration : 269 Training Loss : 70.52016691493023\n",
      "Test Iteration : 269 Test Loss : 70.8040067401211\n",
      "Train Iteration : 270 Training Loss : 69.10651220796677\n",
      "Test Iteration : 270 Test Loss : 69.39229534631274\n",
      "Train Iteration : 271 Training Loss : 68.97296076605076\n",
      "Test Iteration : 271 Test Loss : 69.2627787565355\n",
      "Train Iteration : 272 Training Loss : 68.96445459239155\n",
      "Test Iteration : 272 Test Loss : 69.25873792228394\n",
      "Train Iteration : 273 Training Loss : 68.39145846517518\n",
      "Test Iteration : 273 Test Loss : 68.66888566717105\n",
      "Train Iteration : 274 Training Loss : 68.64454480535686\n",
      "Test Iteration : 274 Test Loss : 68.94705318114204\n",
      "Train Iteration : 275 Training Loss : 69.04641553317165\n",
      "Test Iteration : 275 Test Loss : 69.3714288549824\n",
      "Train Iteration : 276 Training Loss : 69.11166551670745\n",
      "Test Iteration : 276 Test Loss : 69.41131646110155\n",
      "Train Iteration : 277 Training Loss : 69.44389092405386\n",
      "Test Iteration : 277 Test Loss : 69.75288525472935\n",
      "Train Iteration : 278 Training Loss : 70.17809799966813\n",
      "Test Iteration : 278 Test Loss : 70.45254357396041\n",
      "Train Iteration : 279 Training Loss : 68.97844982519548\n",
      "Test Iteration : 279 Test Loss : 69.2867184752618\n",
      "Train Iteration : 280 Training Loss : 68.80384866242858\n",
      "Test Iteration : 280 Test Loss : 69.11989618588426\n",
      "Train Iteration : 281 Training Loss : 68.08616320553206\n",
      "Test Iteration : 281 Test Loss : 68.40489706442074\n",
      "Train Iteration : 282 Training Loss : 67.98810949826311\n",
      "Test Iteration : 282 Test Loss : 68.30784826867519\n",
      "Train Iteration : 283 Training Loss : 68.83406249535577\n",
      "Test Iteration : 283 Test Loss : 69.16766267250134\n",
      "Train Iteration : 284 Training Loss : 68.5484968477315\n",
      "Test Iteration : 284 Test Loss : 68.86667690771966\n",
      "Train Iteration : 285 Training Loss : 69.06617302614504\n",
      "Test Iteration : 285 Test Loss : 69.35097038242193\n",
      "Train Iteration : 286 Training Loss : 68.75827529260313\n",
      "Test Iteration : 286 Test Loss : 69.08482363613989\n",
      "Train Iteration : 287 Training Loss : 68.50874678344287\n",
      "Test Iteration : 287 Test Loss : 68.82146212427793\n",
      "Train Iteration : 288 Training Loss : 68.14422607401137\n",
      "Test Iteration : 288 Test Loss : 68.48145888320074\n",
      "Train Iteration : 289 Training Loss : 67.8982978258144\n",
      "Test Iteration : 289 Test Loss : 68.23233005283619\n",
      "Train Iteration : 290 Training Loss : 67.52485982142326\n",
      "Test Iteration : 290 Test Loss : 67.85131408626924\n",
      "Train Iteration : 291 Training Loss : 67.60843042831479\n",
      "Test Iteration : 291 Test Loss : 67.94865698352494\n",
      "Train Iteration : 292 Training Loss : 67.29308134645851\n",
      "Test Iteration : 292 Test Loss : 67.63716636007709\n",
      "Train Iteration : 293 Training Loss : 67.23278697659953\n",
      "Test Iteration : 293 Test Loss : 67.56526188219378\n",
      "Train Iteration : 294 Training Loss : 67.32987275926622\n",
      "Test Iteration : 294 Test Loss : 67.67068002151278\n",
      "Train Iteration : 295 Training Loss : 67.31050374285999\n",
      "Test Iteration : 295 Test Loss : 67.66779492330876\n",
      "Train Iteration : 296 Training Loss : 67.57941313908957\n",
      "Test Iteration : 296 Test Loss : 67.92287035887561\n",
      "Train Iteration : 297 Training Loss : 68.18665780701059\n",
      "Test Iteration : 297 Test Loss : 68.52169553465491\n",
      "Train Iteration : 298 Training Loss : 69.87872146800157\n",
      "Test Iteration : 298 Test Loss : 70.18912623761125\n",
      "Train Iteration : 299 Training Loss : 70.46057762097058\n",
      "Test Iteration : 299 Test Loss : 70.79474696701017\n",
      "Train Iteration : 300 Training Loss : 71.3867469673479\n",
      "Test Iteration : 300 Test Loss : 71.66280133667061\n",
      "Train Iteration : 301 Training Loss : 67.8162881359206\n",
      "Test Iteration : 301 Test Loss : 68.1547806894609\n",
      "Train Iteration : 302 Training Loss : 67.81108024671876\n",
      "Test Iteration : 302 Test Loss : 68.1764892236359\n",
      "Train Iteration : 303 Training Loss : 69.75492355807532\n",
      "Test Iteration : 303 Test Loss : 70.06674399610898\n",
      "Train Iteration : 304 Training Loss : 68.92080170023283\n",
      "Test Iteration : 304 Test Loss : 69.26439452816817\n",
      "Train Iteration : 305 Training Loss : 67.91917038122467\n",
      "Test Iteration : 305 Test Loss : 68.27653958259233\n",
      "Train Iteration : 306 Training Loss : 67.12672668403152\n",
      "Test Iteration : 306 Test Loss : 67.4711845282873\n",
      "Train Iteration : 307 Training Loss : 68.23473883371041\n",
      "Test Iteration : 307 Test Loss : 68.59493557886701\n",
      "Train Iteration : 308 Training Loss : 68.73432283893388\n",
      "Test Iteration : 308 Test Loss : 69.10083925979626\n",
      "Train Iteration : 309 Training Loss : 67.58136264958901\n",
      "Test Iteration : 309 Test Loss : 67.94754277244881\n",
      "Train Iteration : 310 Training Loss : 67.11125093136354\n",
      "Test Iteration : 310 Test Loss : 67.45321046677586\n",
      "Train Iteration : 311 Training Loss : 67.17742411154367\n",
      "Test Iteration : 311 Test Loss : 67.5340802747899\n",
      "Train Iteration : 312 Training Loss : 67.88953021641223\n",
      "Test Iteration : 312 Test Loss : 68.27347603169163\n",
      "Train Iteration : 313 Training Loss : 67.25919590509214\n",
      "Test Iteration : 313 Test Loss : 67.61746994552821\n",
      "Train Iteration : 314 Training Loss : 66.75994630802766\n",
      "Test Iteration : 314 Test Loss : 67.13130695915802\n",
      "Train Iteration : 315 Training Loss : 66.89549264022541\n",
      "Test Iteration : 315 Test Loss : 67.29829006213674\n",
      "Train Iteration : 316 Training Loss : 67.01255737476137\n",
      "Test Iteration : 316 Test Loss : 67.39999645037202\n",
      "Train Iteration : 317 Training Loss : 67.29062078221122\n",
      "Test Iteration : 317 Test Loss : 67.66381213175165\n",
      "Train Iteration : 318 Training Loss : 67.14366779344189\n",
      "Test Iteration : 318 Test Loss : 67.51218268194668\n",
      "Train Iteration : 319 Training Loss : 66.75722263136855\n",
      "Test Iteration : 319 Test Loss : 67.15469602643806\n",
      "Train Iteration : 320 Training Loss : 66.70567848420167\n",
      "Test Iteration : 320 Test Loss : 67.0829308698571\n",
      "Train Iteration : 321 Training Loss : 66.15413343194474\n",
      "Test Iteration : 321 Test Loss : 66.5614834139886\n",
      "Train Iteration : 322 Training Loss : 66.42580700960384\n",
      "Test Iteration : 322 Test Loss : 66.8339524625058\n",
      "Train Iteration : 323 Training Loss : 66.72960163293409\n",
      "Test Iteration : 323 Test Loss : 67.10167905411377\n",
      "Train Iteration : 324 Training Loss : 66.55151073928097\n",
      "Test Iteration : 324 Test Loss : 66.96780786153275\n",
      "Train Iteration : 325 Training Loss : 67.0021160743\n",
      "Test Iteration : 325 Test Loss : 67.40077090926209\n",
      "Train Iteration : 326 Training Loss : 66.74507423711854\n",
      "Test Iteration : 326 Test Loss : 67.13234014886424\n",
      "Train Iteration : 327 Training Loss : 66.8200372505387\n",
      "Test Iteration : 327 Test Loss : 67.21585283322474\n",
      "Train Iteration : 328 Training Loss : 66.6883882603986\n",
      "Test Iteration : 328 Test Loss : 67.10263849006228\n",
      "Train Iteration : 329 Training Loss : 66.50279514954424\n",
      "Test Iteration : 329 Test Loss : 66.87866985712365\n",
      "Train Iteration : 330 Training Loss : 66.4448032896746\n",
      "Test Iteration : 330 Test Loss : 66.85016235782996\n",
      "Train Iteration : 331 Training Loss : 66.3208326288809\n",
      "Test Iteration : 331 Test Loss : 66.7350288715759\n",
      "Train Iteration : 332 Training Loss : 66.09956316500543\n",
      "Test Iteration : 332 Test Loss : 66.51061768836233\n",
      "Train Iteration : 333 Training Loss : 66.21961949152744\n",
      "Test Iteration : 333 Test Loss : 66.6242156532157\n",
      "Train Iteration : 334 Training Loss : 66.16506862107205\n",
      "Test Iteration : 334 Test Loss : 66.58471428533741\n",
      "Train Iteration : 335 Training Loss : 66.49315790092996\n",
      "Test Iteration : 335 Test Loss : 66.90128907021156\n",
      "Train Iteration : 336 Training Loss : 66.37049839369031\n",
      "Test Iteration : 336 Test Loss : 66.77518047636065\n",
      "Train Iteration : 337 Training Loss : 66.53053733136612\n",
      "Test Iteration : 337 Test Loss : 66.9260264653359\n",
      "Train Iteration : 338 Training Loss : 66.68563198022508\n",
      "Test Iteration : 338 Test Loss : 67.10826433792721\n",
      "Train Iteration : 339 Training Loss : 67.17864163047092\n",
      "Test Iteration : 339 Test Loss : 67.55916298764524\n",
      "Train Iteration : 340 Training Loss : 66.41772305611796\n",
      "Test Iteration : 340 Test Loss : 66.8313325381207\n",
      "Train Iteration : 341 Training Loss : 66.30603399329536\n",
      "Test Iteration : 341 Test Loss : 66.7233143950106\n",
      "Train Iteration : 342 Training Loss : 65.91469483794637\n",
      "Test Iteration : 342 Test Loss : 66.33867904992255\n",
      "Train Iteration : 343 Training Loss : 65.53541435562688\n",
      "Test Iteration : 343 Test Loss : 65.97866353158462\n",
      "Train Iteration : 344 Training Loss : 65.37087063287659\n",
      "Test Iteration : 344 Test Loss : 65.79465840464205\n",
      "Train Iteration : 345 Training Loss : 65.25036584266131\n",
      "Test Iteration : 345 Test Loss : 65.67574728543293\n",
      "Train Iteration : 346 Training Loss : 65.4988217802102\n",
      "Test Iteration : 346 Test Loss : 65.94983678851814\n",
      "Train Iteration : 347 Training Loss : 65.73564423326653\n",
      "Test Iteration : 347 Test Loss : 66.17230245837949\n",
      "Train Iteration : 348 Training Loss : 65.94092630956536\n",
      "Test Iteration : 348 Test Loss : 66.37236453309733\n",
      "Train Iteration : 349 Training Loss : 66.09399408418284\n",
      "Test Iteration : 349 Test Loss : 66.51888949224205\n",
      "Train Iteration : 350 Training Loss : 67.01978015364294\n",
      "Test Iteration : 350 Test Loss : 67.43015838830009\n",
      "Train Iteration : 351 Training Loss : 66.6975006246969\n",
      "Test Iteration : 351 Test Loss : 67.12473400437825\n",
      "Train Iteration : 352 Training Loss : 66.49584164999415\n",
      "Test Iteration : 352 Test Loss : 66.90361877150438\n",
      "Train Iteration : 353 Training Loss : 65.70170370067916\n",
      "Test Iteration : 353 Test Loss : 66.1364790822651\n",
      "Train Iteration : 354 Training Loss : 65.423616223762\n",
      "Test Iteration : 354 Test Loss : 65.87560673462679\n",
      "Train Iteration : 355 Training Loss : 65.09778172489325\n",
      "Test Iteration : 355 Test Loss : 65.53684085039312\n",
      "Train Iteration : 356 Training Loss : 64.8198771646848\n",
      "Test Iteration : 356 Test Loss : 65.26383460653255\n",
      "Train Iteration : 357 Training Loss : 64.89637831138656\n",
      "Test Iteration : 357 Test Loss : 65.35136893713003\n",
      "Train Iteration : 358 Training Loss : 65.22388955244342\n",
      "Test Iteration : 358 Test Loss : 65.66997661018338\n",
      "Train Iteration : 359 Training Loss : 65.55144630491772\n",
      "Test Iteration : 359 Test Loss : 65.99639711876833\n",
      "Train Iteration : 360 Training Loss : 65.58026325105939\n",
      "Test Iteration : 360 Test Loss : 66.02239386203449\n",
      "Train Iteration : 361 Training Loss : 66.35182943655602\n",
      "Test Iteration : 361 Test Loss : 66.77144710445344\n",
      "Train Iteration : 362 Training Loss : 66.26309581471453\n",
      "Test Iteration : 362 Test Loss : 66.69682199833119\n",
      "Train Iteration : 363 Training Loss : 66.09136733490635\n",
      "Test Iteration : 363 Test Loss : 66.51112522687232\n",
      "Train Iteration : 364 Training Loss : 65.32597442016885\n",
      "Test Iteration : 364 Test Loss : 65.76244671448464\n",
      "Train Iteration : 365 Training Loss : 65.05304324184632\n",
      "Test Iteration : 365 Test Loss : 65.5138703034465\n",
      "Train Iteration : 366 Training Loss : 64.6243513977988\n",
      "Test Iteration : 366 Test Loss : 65.07292684016574\n",
      "Train Iteration : 367 Training Loss : 64.42007943387834\n",
      "Test Iteration : 367 Test Loss : 64.87528335391487\n",
      "Train Iteration : 368 Training Loss : 64.66474821040087\n",
      "Test Iteration : 368 Test Loss : 65.12564101142331\n",
      "Train Iteration : 369 Training Loss : 64.98566415761134\n",
      "Test Iteration : 369 Test Loss : 65.43778490392278\n",
      "Train Iteration : 370 Training Loss : 65.48193303315911\n",
      "Test Iteration : 370 Test Loss : 65.93242564316144\n",
      "Train Iteration : 371 Training Loss : 65.62181816490975\n",
      "Test Iteration : 371 Test Loss : 66.0673452615341\n",
      "Train Iteration : 372 Training Loss : 66.40669667200771\n",
      "Test Iteration : 372 Test Loss : 66.82146366511618\n",
      "Train Iteration : 373 Training Loss : 65.70155379613291\n",
      "Test Iteration : 373 Test Loss : 66.14207641400532\n",
      "Train Iteration : 374 Training Loss : 64.99667518972461\n",
      "Test Iteration : 374 Test Loss : 65.43829637208994\n",
      "Train Iteration : 375 Training Loss : 64.44855463015833\n",
      "Test Iteration : 375 Test Loss : 64.89449297307418\n",
      "Train Iteration : 376 Training Loss : 64.34792312110866\n",
      "Test Iteration : 376 Test Loss : 64.82334633509608\n",
      "Train Iteration : 377 Training Loss : 64.46738158517455\n",
      "Test Iteration : 377 Test Loss : 64.91776339604577\n",
      "Train Iteration : 378 Training Loss : 64.52052659042175\n",
      "Test Iteration : 378 Test Loss : 64.97896750436651\n",
      "Train Iteration : 379 Training Loss : 64.7037153525819\n",
      "Test Iteration : 379 Test Loss : 65.17109542484461\n",
      "Train Iteration : 380 Training Loss : 65.25777684504978\n",
      "Test Iteration : 380 Test Loss : 65.70872580154068\n",
      "Train Iteration : 381 Training Loss : 66.02781446482892\n",
      "Test Iteration : 381 Test Loss : 66.47752933436045\n",
      "Train Iteration : 382 Training Loss : 65.40132501767202\n",
      "Test Iteration : 382 Test Loss : 65.84046128471334\n",
      "Train Iteration : 383 Training Loss : 65.29188514828928\n",
      "Test Iteration : 383 Test Loss : 65.73156737548211\n",
      "Train Iteration : 384 Training Loss : 64.86046723063973\n",
      "Test Iteration : 384 Test Loss : 65.3202005569006\n",
      "Train Iteration : 385 Training Loss : 64.23963336299443\n",
      "Test Iteration : 385 Test Loss : 64.69480731729921\n",
      "Train Iteration : 386 Training Loss : 63.87942560556332\n",
      "Test Iteration : 386 Test Loss : 64.35392906229137\n",
      "Train Iteration : 387 Training Loss : 64.19624020392075\n",
      "Test Iteration : 387 Test Loss : 64.68094010495673\n",
      "Train Iteration : 388 Training Loss : 64.44028573892774\n",
      "Test Iteration : 388 Test Loss : 64.89716308842672\n",
      "Train Iteration : 389 Training Loss : 64.55324996790462\n",
      "Test Iteration : 389 Test Loss : 65.01693893069299\n",
      "Train Iteration : 390 Training Loss : 65.03245213340239\n",
      "Test Iteration : 390 Test Loss : 65.49310640161863\n",
      "Train Iteration : 391 Training Loss : 65.31571817397061\n",
      "Test Iteration : 391 Test Loss : 65.77287084902262\n",
      "Train Iteration : 392 Training Loss : 65.41627625964604\n",
      "Test Iteration : 392 Test Loss : 65.87125452294363\n",
      "Train Iteration : 393 Training Loss : 64.73202009308649\n",
      "Test Iteration : 393 Test Loss : 65.18010936997834\n",
      "Train Iteration : 394 Training Loss : 64.44825270783772\n",
      "Test Iteration : 394 Test Loss : 64.90844462171508\n",
      "Train Iteration : 395 Training Loss : 64.01344024906425\n",
      "Test Iteration : 395 Test Loss : 64.49022289688212\n",
      "Train Iteration : 396 Training Loss : 63.76725891448171\n",
      "Test Iteration : 396 Test Loss : 64.22971589744388\n",
      "Train Iteration : 397 Training Loss : 63.78447879249388\n",
      "Test Iteration : 397 Test Loss : 64.27142398429352\n",
      "Train Iteration : 398 Training Loss : 64.05584016022134\n",
      "Test Iteration : 398 Test Loss : 64.54871332962072\n",
      "Train Iteration : 399 Training Loss : 64.20354659868099\n",
      "Test Iteration : 399 Test Loss : 64.67211203018306\n",
      "Train Iteration : 400 Training Loss : 64.56518055615925\n",
      "Test Iteration : 400 Test Loss : 65.0289426552583\n",
      "Train Iteration : 401 Training Loss : 65.41330695518657\n",
      "Test Iteration : 401 Test Loss : 65.8651029929558\n",
      "Train Iteration : 402 Training Loss : 64.76642228432029\n",
      "Test Iteration : 402 Test Loss : 65.23251071405636\n",
      "Train Iteration : 403 Training Loss : 64.51542481936231\n",
      "Test Iteration : 403 Test Loss : 64.98941134654919\n",
      "Train Iteration : 404 Training Loss : 64.3694029865244\n",
      "Test Iteration : 404 Test Loss : 64.81458496875281\n",
      "Train Iteration : 405 Training Loss : 64.01222692719442\n",
      "Test Iteration : 405 Test Loss : 64.48157758925345\n",
      "Train Iteration : 406 Training Loss : 63.577617900233406\n",
      "Test Iteration : 406 Test Loss : 64.06647030381878\n",
      "Train Iteration : 407 Training Loss : 63.61061513168541\n",
      "Test Iteration : 407 Test Loss : 64.09194173991676\n",
      "Train Iteration : 408 Training Loss : 63.51732452263011\n",
      "Test Iteration : 408 Test Loss : 64.00949496495572\n",
      "Train Iteration : 409 Training Loss : 63.4713416110631\n",
      "Test Iteration : 409 Test Loss : 63.96046308269864\n",
      "Train Iteration : 410 Training Loss : 63.361160438271746\n",
      "Test Iteration : 410 Test Loss : 63.86643163490386\n",
      "Train Iteration : 411 Training Loss : 63.382625666118074\n",
      "Test Iteration : 411 Test Loss : 63.870138433471205\n",
      "Train Iteration : 412 Training Loss : 63.25534586611132\n",
      "Test Iteration : 412 Test Loss : 63.74795843245266\n",
      "Train Iteration : 413 Training Loss : 63.26325706508322\n",
      "Test Iteration : 413 Test Loss : 63.76963143007087\n",
      "Train Iteration : 414 Training Loss : 63.268011315732956\n",
      "Test Iteration : 414 Test Loss : 63.7442825222581\n",
      "Train Iteration : 415 Training Loss : 63.29243749918211\n",
      "Test Iteration : 415 Test Loss : 63.800867076477395\n",
      "Train Iteration : 416 Training Loss : 63.18888157390533\n",
      "Test Iteration : 416 Test Loss : 63.6879867916223\n",
      "Train Iteration : 417 Training Loss : 63.07107659834352\n",
      "Test Iteration : 417 Test Loss : 63.583007088958865\n",
      "Train Iteration : 418 Training Loss : 63.109151543907885\n",
      "Test Iteration : 418 Test Loss : 63.60329078268773\n",
      "Train Iteration : 419 Training Loss : 63.094962461966354\n",
      "Test Iteration : 419 Test Loss : 63.599022181159924\n",
      "Train Iteration : 420 Training Loss : 63.27436034098519\n",
      "Test Iteration : 420 Test Loss : 63.78315138417332\n",
      "Train Iteration : 421 Training Loss : 63.79954425103076\n",
      "Test Iteration : 421 Test Loss : 64.28784992013533\n",
      "Train Iteration : 422 Training Loss : 66.39218599324558\n",
      "Test Iteration : 422 Test Loss : 66.8572529540505\n",
      "Train Iteration : 423 Training Loss : 69.43087093590131\n",
      "Test Iteration : 423 Test Loss : 69.85155331716608\n",
      "Train Iteration : 424 Training Loss : 72.10240810592398\n",
      "Test Iteration : 424 Test Loss : 72.48123669724846\n",
      "Train Iteration : 425 Training Loss : 64.38957066176097\n",
      "Test Iteration : 425 Test Loss : 64.81898152581635\n",
      "Train Iteration : 426 Training Loss : 69.57111090804715\n",
      "Test Iteration : 426 Test Loss : 69.94760309672449\n",
      "Train Iteration : 427 Training Loss : 72.52231453094221\n",
      "Test Iteration : 427 Test Loss : 72.89174273741588\n",
      "Train Iteration : 428 Training Loss : 66.20227283954338\n",
      "Test Iteration : 428 Test Loss : 66.60237048379565\n",
      "Train Iteration : 429 Training Loss : 73.92338888033177\n",
      "Test Iteration : 429 Test Loss : 74.2631029021545\n",
      "Train Iteration : 430 Training Loss : 67.38972872270647\n",
      "Test Iteration : 430 Test Loss : 67.79285213532025\n",
      "Train Iteration : 431 Training Loss : 68.18492228089333\n",
      "Test Iteration : 431 Test Loss : 68.54102271842204\n",
      "Train Iteration : 432 Training Loss : 68.20035730941352\n",
      "Test Iteration : 432 Test Loss : 68.6200965049909\n",
      "Train Iteration : 433 Training Loss : 65.90771439972815\n",
      "Test Iteration : 433 Test Loss : 66.35047140326367\n",
      "Train Iteration : 434 Training Loss : 68.88190301840685\n",
      "Test Iteration : 434 Test Loss : 69.30493025133724\n",
      "Train Iteration : 435 Training Loss : 65.14808402402285\n",
      "Test Iteration : 435 Test Loss : 65.57814867397468\n",
      "Train Iteration : 436 Training Loss : 68.47455116525825\n",
      "Test Iteration : 436 Test Loss : 68.87481027773988\n",
      "Train Iteration : 437 Training Loss : 64.88968172857699\n",
      "Test Iteration : 437 Test Loss : 65.3495173324596\n",
      "Train Iteration : 438 Training Loss : 66.6123152201645\n",
      "Test Iteration : 438 Test Loss : 67.02780649377418\n",
      "Train Iteration : 439 Training Loss : 65.34915012607928\n",
      "Test Iteration : 439 Test Loss : 65.7801037509146\n",
      "Train Iteration : 440 Training Loss : 65.14427829536334\n",
      "Test Iteration : 440 Test Loss : 65.61091500554694\n",
      "Train Iteration : 441 Training Loss : 65.49935499397205\n",
      "Test Iteration : 441 Test Loss : 65.94867051221942\n",
      "Train Iteration : 442 Training Loss : 64.32147209077563\n",
      "Test Iteration : 442 Test Loss : 64.79763099543355\n",
      "Train Iteration : 443 Training Loss : 65.69268487447454\n",
      "Test Iteration : 443 Test Loss : 66.12409231622375\n",
      "Train Iteration : 444 Training Loss : 64.06953250639279\n",
      "Test Iteration : 444 Test Loss : 64.537802851862\n",
      "Train Iteration : 445 Training Loss : 64.71965332550454\n",
      "Test Iteration : 445 Test Loss : 65.16661617607248\n",
      "Train Iteration : 446 Training Loss : 64.02342271488128\n",
      "Test Iteration : 446 Test Loss : 64.49174014599039\n",
      "Train Iteration : 447 Training Loss : 64.11138304869672\n",
      "Test Iteration : 447 Test Loss : 64.5898713781178\n",
      "Train Iteration : 448 Training Loss : 63.868066516047435\n",
      "Test Iteration : 448 Test Loss : 64.34349471730822\n",
      "Train Iteration : 449 Training Loss : 63.88754035176979\n",
      "Test Iteration : 449 Test Loss : 64.36810914387509\n",
      "Train Iteration : 450 Training Loss : 63.595729586384785\n",
      "Test Iteration : 450 Test Loss : 64.0924045142445\n",
      "Train Iteration : 451 Training Loss : 63.69125752867932\n",
      "Test Iteration : 451 Test Loss : 64.19435028911607\n",
      "Train Iteration : 452 Training Loss : 63.367111493295795\n",
      "Test Iteration : 452 Test Loss : 63.8613612170483\n",
      "Train Iteration : 453 Training Loss : 63.43078774687114\n",
      "Test Iteration : 453 Test Loss : 63.91843252784476\n",
      "Train Iteration : 454 Training Loss : 63.23453204453485\n",
      "Test Iteration : 454 Test Loss : 63.723190958052\n",
      "Train Iteration : 455 Training Loss : 63.301993543794175\n",
      "Test Iteration : 455 Test Loss : 63.81695438307353\n",
      "Train Iteration : 456 Training Loss : 63.07838193388705\n",
      "Test Iteration : 456 Test Loss : 63.583722562893385\n",
      "Train Iteration : 457 Training Loss : 63.16239606063804\n",
      "Test Iteration : 457 Test Loss : 63.647363547806876\n",
      "Train Iteration : 458 Training Loss : 62.99824966871738\n",
      "Test Iteration : 458 Test Loss : 63.503931637643674\n",
      "Train Iteration : 459 Training Loss : 62.909181627790865\n",
      "Test Iteration : 459 Test Loss : 63.425750390086755\n",
      "Train Iteration : 460 Training Loss : 62.86364970934032\n",
      "Test Iteration : 460 Test Loss : 63.37269862719758\n",
      "Train Iteration : 461 Training Loss : 62.886482829964905\n",
      "Test Iteration : 461 Test Loss : 63.40772697114807\n",
      "Train Iteration : 462 Training Loss : 62.75193668342144\n",
      "Test Iteration : 462 Test Loss : 63.280539706276834\n",
      "Train Iteration : 463 Training Loss : 62.666106889072246\n",
      "Test Iteration : 463 Test Loss : 63.18158590258192\n",
      "Train Iteration : 464 Training Loss : 62.677066636379514\n",
      "Test Iteration : 464 Test Loss : 63.19100480364477\n",
      "Train Iteration : 465 Training Loss : 62.6854083091407\n",
      "Test Iteration : 465 Test Loss : 63.20678233164548\n",
      "Train Iteration : 466 Training Loss : 62.572218884017765\n",
      "Test Iteration : 466 Test Loss : 63.09915063358729\n",
      "Train Iteration : 467 Training Loss : 62.55173666224828\n",
      "Test Iteration : 467 Test Loss : 63.07944191487727\n",
      "Train Iteration : 468 Training Loss : 62.48972453743893\n",
      "Test Iteration : 468 Test Loss : 63.015828087466325\n",
      "Train Iteration : 469 Training Loss : 62.470969707489424\n",
      "Test Iteration : 469 Test Loss : 63.003174054063976\n",
      "Train Iteration : 470 Training Loss : 62.41431198238997\n",
      "Test Iteration : 470 Test Loss : 62.938298228430355\n",
      "Train Iteration : 471 Training Loss : 62.38253703700743\n",
      "Test Iteration : 471 Test Loss : 62.91132061929165\n",
      "Train Iteration : 472 Training Loss : 62.415910713653176\n",
      "Test Iteration : 472 Test Loss : 62.94861912334292\n",
      "Train Iteration : 473 Training Loss : 62.33568220596741\n",
      "Test Iteration : 473 Test Loss : 62.85694234783416\n",
      "Train Iteration : 474 Training Loss : 62.3522984704322\n",
      "Test Iteration : 474 Test Loss : 62.88856223686712\n",
      "Train Iteration : 475 Training Loss : 62.35168123861236\n",
      "Test Iteration : 475 Test Loss : 62.88178514139672\n",
      "Train Iteration : 476 Training Loss : 62.34552213772343\n",
      "Test Iteration : 476 Test Loss : 62.887710753112685\n",
      "Train Iteration : 477 Training Loss : 62.36315818231527\n",
      "Test Iteration : 477 Test Loss : 62.884327453989805\n",
      "Train Iteration : 478 Training Loss : 62.497463788012865\n",
      "Test Iteration : 478 Test Loss : 63.035795545761495\n",
      "Train Iteration : 479 Training Loss : 62.68987556877363\n",
      "Test Iteration : 479 Test Loss : 63.20725537107315\n",
      "Train Iteration : 480 Training Loss : 63.17394787952107\n",
      "Test Iteration : 480 Test Loss : 63.69442610319416\n",
      "Train Iteration : 481 Training Loss : 63.35642732997931\n",
      "Test Iteration : 481 Test Loss : 63.86847936006206\n",
      "Train Iteration : 482 Training Loss : 63.86193975268966\n",
      "Test Iteration : 482 Test Loss : 64.37740494068753\n",
      "Train Iteration : 483 Training Loss : 63.20104443499724\n",
      "Test Iteration : 483 Test Loss : 63.70630268213554\n",
      "Train Iteration : 484 Training Loss : 62.70583699330852\n",
      "Test Iteration : 484 Test Loss : 63.236598350443856\n",
      "Train Iteration : 485 Training Loss : 62.214581239712054\n",
      "Test Iteration : 485 Test Loss : 62.746869684663274\n",
      "Train Iteration : 486 Training Loss : 62.06332786944765\n",
      "Test Iteration : 486 Test Loss : 62.60394519388364\n",
      "Train Iteration : 487 Training Loss : 62.07696962743129\n",
      "Test Iteration : 487 Test Loss : 62.62568339935869\n",
      "Train Iteration : 488 Training Loss : 62.15602516403089\n",
      "Test Iteration : 488 Test Loss : 62.69589567452862\n",
      "Train Iteration : 489 Training Loss : 62.42923537331786\n",
      "Test Iteration : 489 Test Loss : 62.96768869588559\n",
      "Train Iteration : 490 Training Loss : 62.67595066561489\n",
      "Test Iteration : 490 Test Loss : 63.20805984057065\n",
      "Train Iteration : 491 Training Loss : 63.11377725133069\n",
      "Test Iteration : 491 Test Loss : 63.63892574017823\n",
      "Train Iteration : 492 Training Loss : 62.801153345526984\n",
      "Test Iteration : 492 Test Loss : 63.32511581441153\n",
      "Train Iteration : 493 Training Loss : 62.662948917920524\n",
      "Test Iteration : 493 Test Loss : 63.20282310549521\n",
      "Train Iteration : 494 Training Loss : 62.282645065255295\n",
      "Test Iteration : 494 Test Loss : 62.80173883258218\n",
      "Train Iteration : 495 Training Loss : 62.00978707445056\n",
      "Test Iteration : 495 Test Loss : 62.55541972122366\n"
     ]
    }
   ],
   "source": [
    "# # for easy multiplication now the shape of X_train(784,60000) and X_test(784,10000)\n",
    "X_train_noisy = tf.cast(tf.transpose(x_train_noisy),tf.float64)\n",
    "X_test_noisy  = tf.cast(tf.transpose(x_test_noisy),tf.float64)\n",
    "X_train =    tf.convert_to_tensor(x_train.T ,dtype= tf.float64)\n",
    "X_test =    tf.convert_to_tensor(x_test.T ,dtype= tf.float64)\n",
    "\n",
    "train_loss_list , test_loss_list,test_predictedYProb = autoencoder_decoder(X_train_noisy,X_train, X_test_noisy ,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zjdPzaXgfxy"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.plot(test_loss_list)\n",
    "plt.title(\"loss\")\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24j0B1Xt9G83"
   },
   "outputs": [],
   "source": [
    "test_pred = tf.transpose(test_predictedYProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1C2Xhbn1gf0i"
   },
   "outputs": [],
   "source": [
    "n = 10  # Number of images to display \n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "\n",
    "    # Display predicted\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(test_pred[i].numpy().reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "     # Display noisy input\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i].numpy().reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOrj7m4igf3a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxG2VOGjgf6S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Question1_3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
